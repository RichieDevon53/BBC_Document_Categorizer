{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inference**\n",
    "\n",
    "Nama : Richie Devon Sumantri\n",
    "\n",
    "Batch : HCK-018\n",
    "\n",
    "Dokumen ini berfungsi untuk melakukan uji coba prediksi data menggunakan data mentah dan model prediksi yang telah dibuat.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Max\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Max\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Max\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Max\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Memuat libraries\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Import libraries tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Import stopword dan lemmaitzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Import preprocessing\n",
    "from function import text_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Model dan Preprocessing Pipeline**\n",
    "\n",
    "Terdiri dari proses memuat model dari dokumen pickle yang terdiri dari dokumen _modelling_ dan _pipeline preprocessing_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Proses memuat model\n",
    "loaded_model = load_model('model.h5')\n",
    "\n",
    "with open('stop_words_english.txt', 'r', encoding=\"utf-8\") as file:\n",
    "\tstop_words_list = file.read().splitlines()\n",
    "\n",
    "with open('max_sen_len.txt', 'r') as f:\n",
    "\tmax_sen_len = int(f.read())\n",
    "\n",
    "with open('total_vocab.txt', 'r') as f:\n",
    "\ttotal_vocab = int(f.read())\n",
    " \n",
    "with open('train.pickle', 'rb') as f:\n",
    "    loaded_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pembuatan Dummy Data**\n",
    "\n",
    "Pada tahap ini akan dilakukan pembuatan data yang akan dicoba prediksi menggunakan model yang telah dibuat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><b><h3>Data Dummy</h3></b></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global financial markets experienced volatilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla has announced record profits for the sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peace talks between Israel and Palestine have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  Global financial markets experienced volatilit...\n",
       "1  Tesla has announced record profits for the sec...\n",
       "2  Peace talks between Israel and Palestine have ..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pembuatan data dummy berisi tiga data\n",
    "dummy_data = [\n",
    "\t{\n",
    "\t\t'data' : 'Global financial markets experienced volatility today as investors reacted to ongoing concerns about rising inflation and its potential impact on economic growth. Central banks around the world are under pressure to adjust monetary policies to curb inflation while supporting recovery efforts.'\n",
    "\t},\n",
    "\t{\n",
    "\t\t'data' : \"Tesla has announced record profits for the second quarter of 2024, driven by surging demand for electric vehicles (EVs) and the expansion of its production facilities. The company's stock rose sharply following the announcement, reflecting investor confidence in Tesla's growth prospects.\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t'data' : \"Peace talks between Israel and Palestine have resumed in Geneva, with international mediators seeking to broker a lasting resolution to the decades-long conflict. The negotiations are seen as a critical opportunity to address core issues such as borders, security, and the status of Jerusalem.\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "# Pengubahan data dummy menjadi dataframe\n",
    "dummy_df = pd.DataFrame(dummy_data)\n",
    "\n",
    "# Menampilkan judul dari dataframe\n",
    "display(HTML('<center><b><h3>Data Dummy</h3></b></center>'))\n",
    "\n",
    "# Menampilkan dataframe\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\text_vectorization.py:340: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(name=name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Persalinan dataframe dummy\n",
    "dummy_df_pre = dummy_df.copy()\n",
    "\n",
    "# Inisialisasi pembuatan stopword bahasa inggris\n",
    "stopword_eng = list(set(stopwords.words('english') + stop_words_list))\n",
    "\n",
    "# Inisialisasi lematization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Proses preprocessing data\n",
    "dummy_df_pre  = dummy_df_pre ['data'].apply(text_preprocessing, stemmer=lemmatizer, stopword=stopword_eng)\n",
    "\n",
    "# Proses Vektorisasi\n",
    "text_vectorization = TextVectorization(max_tokens=total_vocab,\n",
    "                                       standardize=\"lower_and_strip_punctuation\",\n",
    "                                       split=\"whitespace\",\n",
    "                                       ngrams=(1,2),\n",
    "                                       output_mode=\"int\",\n",
    "                                       output_sequence_length=max_sen_len,\n",
    "                                       encoding='utf-8',\n",
    "                                       input_shape=(1,)) \n",
    "text_vectorization.adapt(loaded_train)\n",
    "\n",
    "# Proses transofrmasi data dummy\n",
    "dummy_df_pre  = text_vectorization(dummy_df_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Predict Data Dummy**\n",
    "\n",
    "Pada tahap ini dilakukan penggabungan keseluruhan data dummy yang akan dilakukan prediksi menggunakan model yang telah dibuat menggunakan data _train_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<center><b><h3>Data Prediksi</h3></b></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Prediction Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global financial markets experienced volatilit...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla has announced record profits for the sec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peace talks between Israel and Palestine have ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data Prediction Label\n",
       "0  Global financial markets experienced volatilit...         business\n",
       "1  Tesla has announced record profits for the sec...         business\n",
       "2  Peace talks between Israel and Palestine have ...             tech"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label target mapping\n",
    "label_mapping = {\n",
    "    0: 'business',\n",
    "    1: 'entertainment',\n",
    "    2: 'politics',\n",
    "    3: 'sport',\n",
    "    4: 'tech'\n",
    "}\n",
    "\n",
    "# Menampilkan prediksi target dari data dummy\n",
    "pred = np.argmax(loaded_model.predict(dummy_df_pre), axis=1)\n",
    "pred_converted = pd.Series(pred).map(label_mapping)\n",
    "\n",
    "# Pengabungan dataframe dummy dengan dataframe prediksi\n",
    "df_concat = pd.concat([dummy_df, pred_converted], axis=1)\n",
    "df_concat.columns = ['data', 'Prediction Label']\n",
    "\n",
    "# Menampilkan hasil prediksi\n",
    "display(HTML('<center><b><h3>Data Prediksi</h3></b></center>'))\n",
    "df_concat\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviroment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
